{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_dataset.targets).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(train_dataset.targets).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['five', 'three', 'two', 'four', 'six', 'seven', 'eight', 'nine'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dik.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "one\n",
      "two\n",
      "three\n",
      "four\n",
      "five\n",
      "six\n",
      "seven\n",
      "eight\n"
     ]
    }
   ],
   "source": [
    "dik={1: 'zero', 1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', 6: 'six', 7: 'seven', 8: 'eight', 9: 'nine'}\n",
    "for i in range(len(dik)):\n",
    "    print(dik.get(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes,arch):\n",
    "        super().__init__()\n",
    "        layerss=[]\n",
    "        sizes=[]\n",
    "        for l, v in arch:\n",
    "            layerss.append(l)\n",
    "            sizes.append(v)\n",
    "        \n",
    "        self.layers=nn.ModuleList()\n",
    "        prev_size= sizes[0]\n",
    "        \n",
    "        #Input layer\n",
    "        self.layers.append(nn.Linear(input_size,prev_size))\n",
    "        #Hidden layers\n",
    "        for i in range(1,len(arch)):\n",
    "            # print(i)\n",
    "            size=sizes[i]\n",
    "            layer=layerss[i]\n",
    "            if layer == 'linear':\n",
    "                self.layers.append(nn.Linear(prev_size,size))\n",
    "            elif layer == 'relu':\n",
    "                self.layers.append(nn.ReLU())\n",
    "            elif layer =='sigmoid':\n",
    "                self.layers.append(nn.Sigmoid())\n",
    "            elif layer == 'batchnorm1d':\n",
    "                self.layers.append(nn.BatchNorm1d(prev_size))\n",
    "            elif layer == 'dropout':\n",
    "                self.layers.append(nn.Dropout())\n",
    "            elif layer == 'flatten':\n",
    "                self.layers.append(nn.Flatten())\n",
    "            if size!=None:\n",
    "                prev_size=size\n",
    "        #Output layer\n",
    "        self.layers.append(nn.Linear(hidden_size,num_classes))\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            out = layer(x)\n",
    "            out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_list = [\n",
    "    ('linear', 128),\n",
    "    ('relu', None),\n",
    "    ('linear', 64),\n",
    "    ('relu', None),\n",
    "    ('linear', 32),\n",
    "    ('relu', None),\n",
    "    ('linear', 16),\n",
    "    ('relu', None),\n",
    "    ('linear', 8),\n",
    "    ('relu', None),\n",
    "    ('linear', 4),\n",
    "    ('relu', None),\n",
    "    ('linear', 2),\n",
    "    ('relu', None),\n",
    "    ('linear', 1),\n",
    "    ('relu', None)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=8, out_features=4, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=4, out_features=2, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Linear(in_features=2, out_features=1, bias=True)\n",
       "    (15): ReLU()\n",
       "    (16): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NN(784, 128, 10,arch=layers_list).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
